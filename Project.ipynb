{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f92887-04ec-4a3c-bf1f-a230c8a0a02a",
   "metadata": {},
   "source": [
    "#### **Install these in command prompt before execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89bdd53a-25c3-4d31-bb9d-e43c8a686839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\li en\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\li en\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\li en\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\li en\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\li en\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: missingno in c:\\users\\li en\\anaconda3\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\li en\\anaconda3\\lib\\site-packages (from missingno) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\li en\\anaconda3\\lib\\site-packages (from missingno) (3.9.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\li en\\anaconda3\\lib\\site-packages (from missingno) (1.13.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\li en\\anaconda3\\lib\\site-packages (from missingno) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from seaborn->missingno) (2.2.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn->missingno) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn->missingno) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\li en\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy \n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install seaborn \n",
    "!pip install missingno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b97723a-58ac-446e-821c-19fd651e6e4a",
   "metadata": {},
   "source": [
    "#### **Import and combine data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a377bd2-8be2-46fd-af73-9c8beaac5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of file paths for the 7 parts\n",
    "file_paths = [f'dataset/uwb_dataset_part{i}.csv' for i in range(1, 8)]\n",
    "\n",
    "# Load each part into a list of DataFrames\n",
    "data_parts = [pd.read_csv(file_path, header=0) for file_path in file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ef55d3-c114-41ae-8a2e-916128375b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NLOS  RANGE  FP_IDX  FP_AMP1  FP_AMP2  FP_AMP3  STDEV_NOISE  CIR_PWR  \\\n",
      "0   0.0   3.90   745.0  18712.0  10250.0  11576.0         64.0  11855.0   \n",
      "1   0.0   0.66   749.0  11239.0   6313.0   4712.0         64.0  18968.0   \n",
      "2   1.0   7.86   746.0   4355.0   5240.0   3478.0         60.0  14699.0   \n",
      "3   1.0   3.48   750.0   8502.0   8416.0   5890.0         76.0   8748.0   \n",
      "4   0.0   1.19   746.0  17845.0  18095.0  12058.0         68.0  11380.0   \n",
      "\n",
      "   MAX_NOISE  RXPACC  ...  CIR1006  CIR1007  CIR1008  CIR1009  CIR1010  \\\n",
      "0      967.0   611.0  ...    279.0    458.0    183.0    158.0    198.0   \n",
      "1     1133.0   447.0  ...    144.0    334.0    290.0    228.0    187.0   \n",
      "2      894.0   723.0  ...     32.0    373.0    224.0    174.0    124.0   \n",
      "3     1127.0  1024.0  ...    252.0    173.0    198.0    160.0    434.0   \n",
      "4     1744.0   276.0  ...    154.0    209.0    242.0    296.0     87.0   \n",
      "\n",
      "   CIR1011  CIR1012  CIR1013  CIR1014  CIR1015  \n",
      "0     87.0    296.0    505.0    307.0      0.0  \n",
      "1    213.0    202.0     89.0    103.0      0.0  \n",
      "2    329.0    207.0     96.0    218.0      0.0  \n",
      "3    397.0    290.0    155.0    342.0    256.0  \n",
      "4    178.0    314.0    247.0    292.0    256.0  \n",
      "\n",
      "[5 rows x 1031 columns]\n",
      "Combined dataset shape: (42000, 1031)\n"
     ]
    }
   ],
   "source": [
    "# Combine all parts into a single DataFrame\n",
    "combined_data = pd.concat(data_parts, ignore_index=True)\n",
    "\n",
    "# Display the combined dataset\n",
    "print(combined_data.head())\n",
    "print(f\"Combined dataset shape: {combined_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e6135ec-9adc-4ad1-8471-f96bc93fa474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 shape: (6000, 1031)\n",
      "Part 2 shape: (6000, 1031)\n",
      "Part 3 shape: (6000, 1031)\n",
      "Part 4 shape: (6000, 1031)\n",
      "Part 5 shape: (6000, 1031)\n",
      "Part 6 shape: (6000, 1031)\n",
      "Part 7 shape: (6000, 1031)\n",
      "Combined dataset shape: (42000, 1031)\n",
      "   NLOS  RANGE  FP_IDX  FP_AMP1  FP_AMP2  FP_AMP3  STDEV_NOISE  CIR_PWR  \\\n",
      "0   0.0   3.90   745.0  18712.0  10250.0  11576.0         64.0  11855.0   \n",
      "1   0.0   0.66   749.0  11239.0   6313.0   4712.0         64.0  18968.0   \n",
      "2   1.0   7.86   746.0   4355.0   5240.0   3478.0         60.0  14699.0   \n",
      "3   1.0   3.48   750.0   8502.0   8416.0   5890.0         76.0   8748.0   \n",
      "4   0.0   1.19   746.0  17845.0  18095.0  12058.0         68.0  11380.0   \n",
      "\n",
      "   MAX_NOISE  RXPACC  ...  CIR1006  CIR1007  CIR1008  CIR1009  CIR1010  \\\n",
      "0      967.0   611.0  ...    279.0    458.0    183.0    158.0    198.0   \n",
      "1     1133.0   447.0  ...    144.0    334.0    290.0    228.0    187.0   \n",
      "2      894.0   723.0  ...     32.0    373.0    224.0    174.0    124.0   \n",
      "3     1127.0  1024.0  ...    252.0    173.0    198.0    160.0    434.0   \n",
      "4     1744.0   276.0  ...    154.0    209.0    242.0    296.0     87.0   \n",
      "\n",
      "   CIR1011  CIR1012  CIR1013  CIR1014  CIR1015  \n",
      "0     87.0    296.0    505.0    307.0      0.0  \n",
      "1    213.0    202.0     89.0    103.0      0.0  \n",
      "2    329.0    207.0     96.0    218.0      0.0  \n",
      "3    397.0    290.0    155.0    342.0    256.0  \n",
      "4    178.0    314.0    247.0    292.0    256.0  \n",
      "\n",
      "[5 rows x 1031 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows in each part\n",
    "for i, part in enumerate(data_parts, start=1):\n",
    "    print(f\"Part {i} shape: {part.shape}\")\n",
    "\n",
    "# Check the combined dataset\n",
    "print(f\"Combined dataset shape: {combined_data.shape}\")\n",
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc498b-a0c4-4113-8b36-c31f95478a16",
   "metadata": {},
   "source": [
    "#### **Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9605de80-862f-4a88-8044-0e540c8cae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "No missing values found.\n"
     ]
    }
   ],
   "source": [
    "# Find columns with missing values\n",
    "missing_values = combined_data.isnull().sum()\n",
    "missing_cols = missing_values[missing_values > 0]\n",
    "print(\"Columns with missing values:\")\n",
    "if not missing_cols.empty:\n",
    "    print(missing_cols)\n",
    "else:\n",
    "    print(\"No missing values found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b87ead-0584-445d-8d45-6ca6def68c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# duplicate rows count\n",
    "duplicate_rows = combined_data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_rows}\")\n",
    "\n",
    "# print duplicate rows if they exist\n",
    "if duplicate_rows > 0:\n",
    "    print(\"Sample duplicate rows:\")\n",
    "    print(combined_data[combined_data.duplicated()].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6836c5a-512c-45d7-beb0-d419b7738f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with only one unique value:\n",
      "CH         1\n",
      "BITRATE    1\n",
      "PRFR       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# find columns with only 1 unique value\n",
    "unique_counts = combined_data.nunique()\n",
    "single_value_cols = unique_counts[unique_counts == 1]\n",
    "print(\"Columns with only one unique value:\")\n",
    "if not single_value_cols.empty:\n",
    "    print(single_value_cols)\n",
    "else:\n",
    "    print(\"No columns with a single unique value.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cdce96b-f8a4-4e09-8589-7dfbb030281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with only one unique value\n",
    "unique_counts = combined_data.nunique()\n",
    "cols_to_drop = unique_counts[unique_counts == 1].index\n",
    "combined_data = combined_data.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d9d9cd-f059-4e2a-8a66-80a88e990352",
   "metadata": {},
   "source": [
    "- CH: only has **ONE** value which is '2'\n",
    "- BITRATE: only has **ONE** value which is '110'\n",
    "- PRFR: only has **ONE** value which is '64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50202d19-f5bd-4f64-9b2e-efa993e68915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Combined dataset shape: (42000, 1028)\n",
      "   NLOS  RANGE  FP_IDX  FP_AMP1  FP_AMP2  FP_AMP3  STDEV_NOISE  CIR_PWR  \\\n",
      "0   0.0   3.90   745.0  18712.0  10250.0  11576.0         64.0  11855.0   \n",
      "1   0.0   0.66   749.0  11239.0   6313.0   4712.0         64.0  18968.0   \n",
      "2   1.0   7.86   746.0   4355.0   5240.0   3478.0         60.0  14699.0   \n",
      "3   1.0   3.48   750.0   8502.0   8416.0   5890.0         76.0   8748.0   \n",
      "4   0.0   1.19   746.0  17845.0  18095.0  12058.0         68.0  11380.0   \n",
      "\n",
      "   MAX_NOISE  RXPACC  ...  CIR1006  CIR1007  CIR1008  CIR1009  CIR1010  \\\n",
      "0      967.0   611.0  ...    279.0    458.0    183.0    158.0    198.0   \n",
      "1     1133.0   447.0  ...    144.0    334.0    290.0    228.0    187.0   \n",
      "2      894.0   723.0  ...     32.0    373.0    224.0    174.0    124.0   \n",
      "3     1127.0  1024.0  ...    252.0    173.0    198.0    160.0    434.0   \n",
      "4     1744.0   276.0  ...    154.0    209.0    242.0    296.0     87.0   \n",
      "\n",
      "   CIR1011  CIR1012  CIR1013  CIR1014  CIR1015  \n",
      "0     87.0    296.0    505.0    307.0      0.0  \n",
      "1    213.0    202.0     89.0    103.0      0.0  \n",
      "2    329.0    207.0     96.0    218.0      0.0  \n",
      "3    397.0    290.0    155.0    342.0    256.0  \n",
      "4    178.0    314.0    247.0    292.0    256.0  \n",
      "\n",
      "[5 rows x 1028 columns]\n"
     ]
    }
   ],
   "source": [
    "# check current combined dataset\n",
    "print(f\"Current Combined dataset shape: {combined_data.shape}\")\n",
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2b27ed9-d781-43a0-a99c-cc97b57267f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Identify non-numeric columns\n",
    "non_numeric_cols = combined_data.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Print non-numeric columns\n",
    "print(\"Non-numeric columns:\")\n",
    "print(non_numeric_cols.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ff73802-a5c7-4d72-b4c9-aa8da9a8226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns containing special characters in values:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Define special characters\n",
    "special_chars = r\"[!@#$%^&*()_\\-?/<>]\"\n",
    "\n",
    "# Find columns with special characters\n",
    "cols_with_special_chars = [col for col in combined_data.columns if combined_data[col].astype(str).str.contains(special_chars, regex=True).any()]\n",
    "\n",
    "# Print columns with special characters\n",
    "print(\"Columns containing special characters in values:\")\n",
    "print(cols_with_special_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31a14a4-1227-4620-aebf-2c65ef88fcc7",
   "metadata": {},
   "source": [
    "#### **PCA for feature reduction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "907e7bd2-3d30-4f98-9b1c-ef4479ef985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the target column 'NLOS' first\n",
    "pca_data = combined_data.drop(columns=[\"NLOS\"]).copy()  # Remove NLOS and create a copy\n",
    "\n",
    "# Step 1: Compute the mean (𝛍) for each column and center the data\n",
    "mean_vals = pca_data.mean(axis=0)  # Compute mean for each feature\n",
    "centered_data = pca_data - mean_vals  # Center the data by subtracting the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "665f1814-c965-4579-af46-a7b3961d8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 2: Calculate the covariance matrix\n",
    "cov_matrix = np.cov(centered_data, rowvar=False)  # Ensure correct shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ed56d86-a10d-45c5-9d4c-d33d2257dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Find eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)  # More stable for symmetric matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89d76de5-5bca-4a7b-ba96-65160bc9c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Sort eigenvectors based on eigenvalues (descending order)\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]  # Get indices of sorted eigenvalues\n",
    "eigenvalues = eigenvalues[sorted_indices]  # Sort eigenvalues\n",
    "eigenvectors = eigenvectors[:, sorted_indices]  # Sort eigenvectors accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c856241-ec36-45c1-898e-46e127288f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Select the top k principal components for dimensionality reduction\n",
    "explained_variance_ratio = eigenvalues / np.sum(eigenvalues)  # Compute variance ratio\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)  # Compute cumulative variance\n",
    "k = np.argmax(cumulative_variance >= 0.95) + 1  # Select k PCs that retain 95% variance\n",
    "top_k_eigenvectors = eigenvectors[:, :k]  # Extract top k eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "994824a4-b700-46d5-b6fe-e7354d35d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Project the data onto the selected principal components\n",
    "pca_transformed_data = np.dot(centered_data, top_k_eigenvectors)  # New dataset with reduced dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59b5f940-69cd-4be6-8c04-4a03f32c6ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign feature names to the principal components\n",
    "# Get the feature names based on the highest absolute value of eigenvectors for each PC\n",
    "original_feature_names = list(pca_data.columns)  # Save original feature names\n",
    "pca_feature_names = [\n",
    "    original_feature_names[np.argmax(np.abs(top_k_eigenvectors[:, i]))]\n",
    "    for i in range(k)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58a77116-3f80-4eae-9066-5299efe2fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert transformed data into a DataFrame with original feature names as column labels\n",
    "pca_df = pd.DataFrame(pca_transformed_data, columns=pca_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abbd37b9-2ab5-400e-8d9c-8ffe39a999de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Shape: (42000, 1027)\n",
      "Reduced Data Shape: (42000, 37)\n",
      "Explained Variance by 37 PCs: 0.9507\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(f\"Original Data Shape: {pca_data.shape}\")\n",
    "print(f\"Reduced Data Shape: {pca_df.shape}\")\n",
    "print(f\"Explained Variance by {k} PCs: {cumulative_variance[k-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea084358-b67b-43f0-be8a-03edda2dfcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Features After PCA:\n",
      "CIR_PWR\n",
      "FP_AMP2\n",
      "CIR746\n",
      "CIR749\n",
      "CIR753\n",
      "CIR751\n",
      "CIR752\n",
      "CIR751\n",
      "FP_AMP1\n",
      "CIR753\n",
      "CIR754\n",
      "CIR755\n",
      "CIR756\n",
      "CIR757\n",
      "CIR756\n",
      "CIR757\n",
      "CIR759\n",
      "CIR760\n",
      "CIR761\n",
      "CIR748\n",
      "CIR761\n",
      "CIR762\n",
      "CIR762\n",
      "CIR763\n",
      "FP_AMP3\n",
      "CIR764\n",
      "CIR765\n",
      "CIR765\n",
      "CIR743\n",
      "CIR770\n",
      "CIR769\n",
      "CIR770\n",
      "CIR771\n",
      "CIR_PWR\n",
      "CIR772\n",
      "CIR776\n",
      "CIR775\n"
     ]
    }
   ],
   "source": [
    "# Columns left after feature reduction\n",
    "print(\"Remaining Features After PCA:\")\n",
    "for col in pca_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95984fab-eea5-40de-a291-6aca1a509230",
   "metadata": {},
   "source": [
    "#### **Data after PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3daacbf1-7241-4797-b951-0cd8137b5416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28)\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicated columns\n",
    "duplicated_columns = pca_df.columns[pca_df.columns.duplicated()].tolist()\n",
    "# Drop duplicated columns\n",
    "pca_df = pca_df.loc[:, ~pca_df.columns.duplicated()]\n",
    "\n",
    "print(pca_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdd7e3b4-15a5-421d-9c4c-0c20fb4b028d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after PCA and adding NLOS:\n",
      "   CIR_PWR  FP_AMP2   CIR746   CIR749   CIR753   CIR751   CIR752  FP_AMP1  \\\n",
      "0  11855.0  10250.0   6102.0   9621.0   6569.0   7763.0   2337.0  18712.0   \n",
      "1  18968.0   6313.0    194.0   1840.0  17764.0  10885.0  17365.0  11239.0   \n",
      "2  14699.0   5240.0   1212.0   4489.0  11277.0   7344.0   8902.0   4355.0   \n",
      "3   8748.0   8416.0    292.0   1424.0  12037.0   5876.0   9544.0   8502.0   \n",
      "4  11380.0  18095.0  11949.0  16162.0   7605.0   1543.0  10785.0  17845.0   \n",
      "\n",
      "    CIR754   CIR755  ...  CIR764  CIR765  CIR743  CIR770  CIR769  CIR771  \\\n",
      "0   8875.0   6793.0  ...  4700.0  4515.0   814.0  1830.0  2288.0  1307.0   \n",
      "1  12565.0  16559.0  ...  6046.0  2636.0   179.0   910.0  4080.0   997.0   \n",
      "2  16809.0   9208.0  ...  9815.0  1207.0   114.0  3219.0  3850.0  1731.0   \n",
      "3   8059.0   5579.0  ...  8974.0  4098.0   223.0  3798.0  3901.0  4361.0   \n",
      "4   4289.0   2524.0  ...  1360.0   454.0    43.0   379.0  1113.0   689.0   \n",
      "\n",
      "   CIR772  CIR776  CIR775  NLOS  \n",
      "0   461.0   400.0   798.0   0.0  \n",
      "1  1262.0  3300.0  6172.0   0.0  \n",
      "2  6272.0  4554.0  3163.0   1.0  \n",
      "3   479.0  1761.0  1057.0   1.0  \n",
      "4   378.0  1027.0  1380.0   0.0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Li En\\AppData\\Local\\Temp\\ipykernel_13148\\860712666.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_pca_data['NLOS'] = combined_data['NLOS']\n"
     ]
    }
   ],
   "source": [
    "# Drop all columns except the ones left after PCA\n",
    "pca_columns = pca_df.columns  # Get the PCA feature columns\n",
    "combined_pca_data = combined_data[pca_columns]  # Retain only those columns in combined_data\n",
    "\n",
    "# Join 'NLOS' column back to the reduced dataset\n",
    "combined_pca_data['NLOS'] = combined_data['NLOS']\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(\"Data after PCA and adding NLOS:\")\n",
    "print(combined_pca_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c07bc5-6d71-4809-8967-90e76bab6c23",
   "metadata": {},
   "source": [
    "#### **Further data cleaning/preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1708d998-b4be-42d7-b99e-eda2014014ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Calculate the IQR (Interquartile Range) for each feature\n",
    "Q1 = combined_pca_data.drop(columns=['NLOS']).quantile(0.25)\n",
    "Q3 = combined_pca_data.drop(columns=['NLOS']).quantile(0.75)\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd8a0dcd-c7a8-49fb-983e-383ec630f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the outlier condition: values that are outside of the IQR range\n",
    "outlier_condition = ((combined_pca_data.drop(columns=['NLOS']) < (Q1 - 1.5 * IQR)) | \n",
    "                     (combined_pca_data.drop(columns=['NLOS']) > (Q3 + 1.5 * IQR)))\n",
    "\n",
    "# Drop rows with any outliers\n",
    "cleaned_combined_pca_data = combined_pca_data[~outlier_condition.any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "877c3d3d-a8fd-4698-a5e9-490b5b7aa6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Shape: (42000, 29)\n",
      "Cleaned Data Shape (after dropping outliers): (25155, 29)\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of the cleaned data\n",
    "print(f\"Original Data Shape: {combined_pca_data.shape}\")\n",
    "print(f\"Cleaned Data Shape (after dropping outliers): {cleaned_combined_pca_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99d3cc-25eb-44ba-b0b4-6d2d015dbe93",
   "metadata": {},
   "source": [
    "#### **jf's PCA portion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3361be1-54c6-482a-a47b-330c1a97d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "for col in combined_data.columns:\n",
    "    if is_numeric_dtype(combined_data[col]):\n",
    "        print('%s:' % (col))\n",
    "        print('\\t Mean = %.2f' % combined_data[col].mean())\n",
    "        print('\\t Standard deviation = %.2f' % combined_data[col].std())\n",
    "        print('\\t Minimum = %.2f' % combined_data[col].min())\n",
    "        print('\\t Maximum = %.2f' % combined_data[col].max())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15668eab-389c-4739-a01f-fb30e7bb3b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd35be2-2bef-4544-9c94-242b6fd0df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariance:')\n",
    "combined_data.cov(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a8099-defc-40a6-9ba6-d6a00b625509",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlation:') \n",
    "combined_data.corr(numeric_only=True) #range -1 to +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed12d0-a1bc-4466-9fad-2f9920f32c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a8825-6c76-4149-a29e-5eaa32a41739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the occurrences of NLOS and LOS\n",
    "nlos_count = combined_data['NLOS'].value_counts()[1]\n",
    "los_count = combined_data['NLOS'].value_counts()[0]\n",
    "\n",
    "# Print the counts\n",
    "print(f'NLOS count: {nlos_count}')\n",
    "print(f'LOS count: {los_count}')\n",
    "\n",
    "# Plot the distribution of the target variable (NLOS)\n",
    "plt.figure(figsize=(6, 4))\n",
    "combined_data['NLOS'].value_counts().plot(kind='bar', color=['blue', 'orange'])\n",
    "plt.title('Distribution of NLOS (0 = LOS, 1 = NLOS)')\n",
    "plt.xlabel('NLOS')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b77593-9e38-40b1-9c83-e53f7844862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all numerical features\n",
    "numerical_features = [\n",
    "    'RANGE', 'FP_IDX', 'FP_AMP1', 'FP_AMP2', 'FP_AMP3', \n",
    "    'STDEV_NOISE', 'CIR_PWR', 'MAX_NOISE', 'RXPACC', \n",
    "    'CH', 'FRAME_LEN', 'PREAM_LEN', 'BITRATE', 'PRFR'\n",
    "]\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(18, 14))\n",
    "for i, feature in enumerate(numerical_features, 1):\n",
    "    plt.subplot(4, 4, i)\n",
    "    plt.hist(combined_data[feature], bins=30, color='blue', alpha=0.7)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "# Adjust layout for readability\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bfa7ab-bfbc-4ffd-b3ad-3659777e084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = combined_data[numerical_features].corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8055cfd4-cf3d-4b8b-a47e-70ef8ad87b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplots for numerical features\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(18, 14))\n",
    "for i, feature in enumerate(numerical_features, 1):\n",
    "    plt.subplot(4, 4, i)\n",
    "    sns.boxplot(y=combined_data[feature], color='orange')\n",
    "    plt.title(f'Boxplot of {feature}')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538131dd-0424-4f4c-96cf-4f66cdcad0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CIR values for a few samples\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(5):  # Plot first 5 samples\n",
    "    plt.plot(combined_data.loc[i, 'CIR1':'CIR1015'], label=f'Sample {i+1}')\n",
    "plt.title('CIR Values for First 5 Samples')\n",
    "plt.xlabel('CIR Index')\n",
    "plt.ylabel('CIR Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e1a29-c98c-4779-9b50-e1c6f0763942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "missing_data = combined_data.isnull().sum()\n",
    "\n",
    "# Display columns with missing values\n",
    "if missing_data.sum() > 0:\n",
    "    print(\"Missing Data:\")\n",
    "    print(missing_data[missing_data > 0])\n",
    "else:\n",
    "    print(\"No missing data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d32863b-ac98-4049-877a-6a043fcb2da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicate_rows = combined_data.duplicated()\n",
    "\n",
    "# Display the number of duplicate rows\n",
    "print(f\"Number of duplicate rows: {duplicate_rows.sum()}\")\n",
    "\n",
    "# Display duplicate rows\n",
    "print(\"Duplicate Data:\")\n",
    "print(combined_data[duplicate_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2341c0-f67e-414a-8aec-aca3d52da39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance of each column\n",
    "variances = combined_data.var()\n",
    "\n",
    "# Identify columns with zero or very low variance\n",
    "low_variance_columns = variances[variances < 1e-10].index.tolist()\n",
    "\n",
    "print(\"Columns with low variance:\")\n",
    "print(low_variance_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893dd709-8e7f-47ab-891f-f44ac040551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with low variance\n",
    "data_cleaned = combined_data.drop(columns=low_variance_columns)\n",
    "\n",
    "print(f\"Shape after dropping low-variance columns: {data_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450c3acb-855d-4998-b5c6-aaf88a05e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "numerical_features = [\n",
    "    'RANGE', 'FP_IDX', 'FP_AMP1', 'FP_AMP2', 'FP_AMP3', \n",
    "    'STDEV_NOISE', 'CIR_PWR', 'MAX_NOISE', 'RXPACC', \n",
    "    'FRAME_LEN', 'PREAM_LEN'\n",
    "]\n",
    "\n",
    "z_scores = data_cleaned[numerical_features].apply(zscore)\n",
    "\n",
    "# Identify outliers (absolute Z-score > 3)\n",
    "outliers = (abs(z_scores) > 3).any(axis=1)\n",
    "\n",
    "# Display rows with outliers\n",
    "print(data_cleaned[outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1472d592-3464-4f69-ad4a-0a33afa802d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with outliers\n",
    "data_cleaned = data_cleaned[~outliers]\n",
    "print(data_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd17d0-1543-414d-a913-f4671d31f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the class attribute (NLOS)\n",
    "data_without_class = combined_data.drop(columns=['NLOS'])\n",
    "\n",
    "# Display the dataset without the class attribute\n",
    "print(data_without_class.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a997e99-0472-4b84-b0c1-0d1818ca173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select non-CIR numerical columns for visualization\n",
    "non_cir_columns = ['RANGE', 'FP_AMP1', 'FP_AMP2', 'FP_AMP3', 'STDEV_NOISE', 'CIR_PWR', 'MAX_NOISE', 'RXPACC', 'CH', 'FRAME_LEN', 'PREAM_LEN', 'BITRATE', 'PRFR']\n",
    "\n",
    "# Plot boxplots for non-CIR numerical columns\n",
    "plt.figure(figsize=(14, 8))\n",
    "data_without_class[non_cir_columns].boxplot()\n",
    "plt.title('Boxplot of Non-CIR Numerical Attributes')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd6c9b-e30a-4196-8259-9e74604623b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance of each column\n",
    "variances = data_without_class.var()\n",
    "\n",
    "# Identify columns with zero or very low variance\n",
    "low_variance_columns = variances[variances < 1e-10].index.tolist()\n",
    "\n",
    "print(\"Columns with low variance:\")\n",
    "print(low_variance_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979eb378-9ece-4756-9ba6-7b8ca964fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with low variance\n",
    "data_without_class = data_without_class.drop(columns=low_variance_columns)\n",
    "\n",
    "print(f\"Shape after dropping low-variance columns: {data_without_class.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84fdae7-ee27-4638-ad85-766494556412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert data to numeric\n",
    "data_numeric = data_without_class.select_dtypes(include=['number'])\n",
    "\n",
    "# 2. Calculate Z-scores\n",
    "Z = (data_numeric - data_numeric.mean()) / data_numeric.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0d263-c2a5-48e0-a657-cd45f6ad4211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Identify and remove outliers\n",
    "print('Number of rows before discarding outliers = %d' % (Z.shape[0]))\n",
    "\n",
    "# Remove rows with any Z-score outside the range [-3, 3]\n",
    "Z2 = Z.loc[((Z > -3).sum(axis=1) == Z.shape[1]) & ((Z <= 3).sum(axis=1) == Z.shape[1]), :]\n",
    "\n",
    "print('Number of rows after discarding outliers = %d' % (Z2.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a8d4a-9833-49cd-a9aa-d9945c68479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data_without_class.loc[Z2.index]\n",
    "# Display the cleaned dataset\n",
    "print(\"Cleaned dataset:\")\n",
    "print(data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9369633-5777-49e7-b600-f140a63db0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# Aggregate CIR columns (CIR1 to CIR1015)\n",
    "# Ensure we are working with a copy of the DataFrame\n",
    "data_cleaned = data_cleaned.copy()\n",
    "\n",
    "# 1. Aggregation\n",
    "# Aggregate CIR columns (CIR1 to CIR1015)\n",
    "cir_columns = [f'CIR{i}' for i in range(1, 1016)]\n",
    "data_cleaned.loc[:, 'CIR_MEAN'] = data_cleaned[cir_columns].mean(axis=1)\n",
    "data_cleaned.loc[:, 'CIR_STD'] = data_cleaned[cir_columns].std(axis=1)\n",
    "data_cleaned.loc[:, 'CIR_MAX'] = data_cleaned[cir_columns].max(axis=1)\n",
    "data_cleaned.loc[:, 'CIR_MIN'] = data_cleaned[cir_columns].min(axis=1)\n",
    "\n",
    "# Drop the original CIR columns (optional)\n",
    "#data_cleaned = data_cleaned.drop(columns=cir_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe31f1c-4eee-4adb-9630-4881dc0eb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Sampling\n",
    "# Randomly sample 10% of the dataset\n",
    "sampled_data = data_cleaned.sample(frac=0.1, random_state=42)\n",
    "print(f\"Shape of sampled dataset: {sampled_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0800ad-7c78-48e1-8bb1-4021f89d40b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 3. Discretization\n",
    "# Discretize the RANGE feature into 5 bins\n",
    "data_cleaned.loc[:, 'RANGE_BIN'] = pd.cut(data_cleaned['RANGE'], bins=5, labels=[\"Very Low\", \"Low\", \"Medium\", \"High\", \"Very High\"])\n",
    "\n",
    "# Discretize the CIR_PWR feature into quartiles\n",
    "data_cleaned.loc[:, 'CIR_PWR_BIN'] = pd.qcut(data_cleaned['CIR_PWR'], q=4, labels=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"])\n",
    "\n",
    "# Display the final dataset\n",
    "print(data_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b2484-b010-4a3e-abb7-863ad876a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778fa222-2d95-4f79-bf45-6ea0c97edaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract CIR columns (CIR1 to CIR1015)\n",
    "cir_columns = [f'CIR{i}' for i in range(1, 1016)]\n",
    "cir_data = data[cir_columns]\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "pca.fit(cir_data)\n",
    "\n",
    "# Plot explained variance ratio\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_.cumsum(), marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by PCA Components')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Choose the number of components that explain >95% of the variance\n",
    "n_components = len(pca.explained_variance_ratio_[pca.explained_variance_ratio_.cumsum() <= 0.95])\n",
    "print(f\"Number of components to retain: {n_components}\")\n",
    "\n",
    "# Apply PCA with selected number of components\n",
    "pca = PCA(n_components=n_components)\n",
    "cir_reduced = pca.fit_transform(cir_data)\n",
    "\n",
    "# Add reduced CIR features back to the dataset\n",
    "for i in range(n_components):\n",
    "    data[f'CIR_PC{i+1}'] = cir_reduced[:, i]\n",
    "\n",
    "# Drop original CIR columns (optional, to save memory)\n",
    "data.drop(columns=cir_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12677000-d229-4310-a3b4-1d31f9c10a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
