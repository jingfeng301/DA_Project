{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f92887-04ec-4a3c-bf1f-a230c8a0a02a",
   "metadata": {},
   "source": [
    "#### **Install these in command prompt before execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bdd53a-25c3-4d31-bb9d-e43c8a686839",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy \n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install seaborn \n",
    "!pip install missingno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b97723a-58ac-446e-821c-19fd651e6e4a",
   "metadata": {},
   "source": [
    "#### **Import and combine data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a377bd2-8be2-46fd-af73-9c8beaac5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of file paths for the 7 parts\n",
    "file_paths = [f'dataset/uwb_dataset_part{i}.csv' for i in range(1, 8)]\n",
    "\n",
    "# Load each part into a list of DataFrames\n",
    "data_parts = [pd.read_csv(file_path, header=0) for file_path in file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ef55d3-c114-41ae-8a2e-916128375b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NLOS  RANGE  FP_IDX  FP_AMP1  FP_AMP2  FP_AMP3  STDEV_NOISE  CIR_PWR  \\\n",
      "0   0.0   3.90   745.0  18712.0  10250.0  11576.0         64.0  11855.0   \n",
      "1   0.0   0.66   749.0  11239.0   6313.0   4712.0         64.0  18968.0   \n",
      "2   1.0   7.86   746.0   4355.0   5240.0   3478.0         60.0  14699.0   \n",
      "3   1.0   3.48   750.0   8502.0   8416.0   5890.0         76.0   8748.0   \n",
      "4   0.0   1.19   746.0  17845.0  18095.0  12058.0         68.0  11380.0   \n",
      "\n",
      "   MAX_NOISE  RXPACC  ...  CIR1006  CIR1007  CIR1008  CIR1009  CIR1010  \\\n",
      "0      967.0   611.0  ...    279.0    458.0    183.0    158.0    198.0   \n",
      "1     1133.0   447.0  ...    144.0    334.0    290.0    228.0    187.0   \n",
      "2      894.0   723.0  ...     32.0    373.0    224.0    174.0    124.0   \n",
      "3     1127.0  1024.0  ...    252.0    173.0    198.0    160.0    434.0   \n",
      "4     1744.0   276.0  ...    154.0    209.0    242.0    296.0     87.0   \n",
      "\n",
      "   CIR1011  CIR1012  CIR1013  CIR1014  CIR1015  \n",
      "0     87.0    296.0    505.0    307.0      0.0  \n",
      "1    213.0    202.0     89.0    103.0      0.0  \n",
      "2    329.0    207.0     96.0    218.0      0.0  \n",
      "3    397.0    290.0    155.0    342.0    256.0  \n",
      "4    178.0    314.0    247.0    292.0    256.0  \n",
      "\n",
      "[5 rows x 1031 columns]\n",
      "Combined dataset shape: (42000, 1031)\n"
     ]
    }
   ],
   "source": [
    "# Combine all parts into a single DataFrame\n",
    "combined_data = pd.concat(data_parts, ignore_index=True)\n",
    "\n",
    "# Display the combined dataset\n",
    "print(combined_data.head())\n",
    "print(f\"Combined dataset shape: {combined_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6135ec-9adc-4ad1-8471-f96bc93fa474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 shape: (6000, 1031)\n",
      "Part 2 shape: (6000, 1031)\n",
      "Part 3 shape: (6000, 1031)\n",
      "Part 4 shape: (6000, 1031)\n",
      "Part 5 shape: (6000, 1031)\n",
      "Part 6 shape: (6000, 1031)\n",
      "Part 7 shape: (6000, 1031)\n",
      "Combined dataset shape: (42000, 1031)\n",
      "   NLOS  RANGE  FP_IDX  FP_AMP1  FP_AMP2  FP_AMP3  STDEV_NOISE  CIR_PWR  \\\n",
      "0   0.0   3.90   745.0  18712.0  10250.0  11576.0         64.0  11855.0   \n",
      "1   0.0   0.66   749.0  11239.0   6313.0   4712.0         64.0  18968.0   \n",
      "2   1.0   7.86   746.0   4355.0   5240.0   3478.0         60.0  14699.0   \n",
      "3   1.0   3.48   750.0   8502.0   8416.0   5890.0         76.0   8748.0   \n",
      "4   0.0   1.19   746.0  17845.0  18095.0  12058.0         68.0  11380.0   \n",
      "\n",
      "   MAX_NOISE  RXPACC  ...  CIR1006  CIR1007  CIR1008  CIR1009  CIR1010  \\\n",
      "0      967.0   611.0  ...    279.0    458.0    183.0    158.0    198.0   \n",
      "1     1133.0   447.0  ...    144.0    334.0    290.0    228.0    187.0   \n",
      "2      894.0   723.0  ...     32.0    373.0    224.0    174.0    124.0   \n",
      "3     1127.0  1024.0  ...    252.0    173.0    198.0    160.0    434.0   \n",
      "4     1744.0   276.0  ...    154.0    209.0    242.0    296.0     87.0   \n",
      "\n",
      "   CIR1011  CIR1012  CIR1013  CIR1014  CIR1015  \n",
      "0     87.0    296.0    505.0    307.0      0.0  \n",
      "1    213.0    202.0     89.0    103.0      0.0  \n",
      "2    329.0    207.0     96.0    218.0      0.0  \n",
      "3    397.0    290.0    155.0    342.0    256.0  \n",
      "4    178.0    314.0    247.0    292.0    256.0  \n",
      "\n",
      "[5 rows x 1031 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows in each part\n",
    "for i, part in enumerate(data_parts, start=1):\n",
    "    print(f\"Part {i} shape: {part.shape}\")\n",
    "\n",
    "# Check the combined dataset\n",
    "print(f\"Combined dataset shape: {combined_data.shape}\")\n",
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc498b-a0c4-4113-8b36-c31f95478a16",
   "metadata": {},
   "source": [
    "#### **Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9605de80-862f-4a88-8044-0e540c8cae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "No missing values found.\n"
     ]
    }
   ],
   "source": [
    "# Find columns with missing values\n",
    "missing_values = combined_data.isnull().sum()\n",
    "missing_cols = missing_values[missing_values > 0]\n",
    "print(\"Columns with missing values:\")\n",
    "if not missing_cols.empty:\n",
    "    print(missing_cols)\n",
    "else:\n",
    "    print(\"No missing values found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44b87ead-0584-445d-8d45-6ca6def68c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# duplicate rows count\n",
    "duplicate_rows = combined_data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_rows}\")\n",
    "\n",
    "# print duplicate rows if they exist\n",
    "if duplicate_rows > 0:\n",
    "    print(\"Sample duplicate rows:\")\n",
    "    print(combined_data[combined_data.duplicated()].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6836c5a-512c-45d7-beb0-d419b7738f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with only one unique value:\n",
      "CH         1\n",
      "BITRATE    1\n",
      "PRFR       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# find columns with only 1 unique value\n",
    "unique_counts = combined_data.nunique()\n",
    "single_value_cols = unique_counts[unique_counts == 1]\n",
    "print(\"Columns with only one unique value:\")\n",
    "if not single_value_cols.empty:\n",
    "    print(single_value_cols)\n",
    "else:\n",
    "    print(\"No columns with a single unique value.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cdce96b-f8a4-4e09-8589-7dfbb030281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with only one unique value\n",
    "unique_counts = combined_data.nunique()\n",
    "cols_to_drop = unique_counts[unique_counts == 1].index\n",
    "combined_data = combined_data.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d9d9cd-f059-4e2a-8a66-80a88e990352",
   "metadata": {},
   "source": [
    "- CH: only has **ONE** value which is '2'\n",
    "- BITRATE: only has **ONE** value which is '110'\n",
    "- PRFR: only has **ONE** value which is '64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50202d19-f5bd-4f64-9b2e-efa993e68915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Combined dataset shape: (42000, 1028)\n",
      "   NLOS  RANGE  FP_IDX  FP_AMP1  FP_AMP2  FP_AMP3  STDEV_NOISE  CIR_PWR  \\\n",
      "0   0.0   3.90   745.0  18712.0  10250.0  11576.0         64.0  11855.0   \n",
      "1   0.0   0.66   749.0  11239.0   6313.0   4712.0         64.0  18968.0   \n",
      "2   1.0   7.86   746.0   4355.0   5240.0   3478.0         60.0  14699.0   \n",
      "3   1.0   3.48   750.0   8502.0   8416.0   5890.0         76.0   8748.0   \n",
      "4   0.0   1.19   746.0  17845.0  18095.0  12058.0         68.0  11380.0   \n",
      "\n",
      "   MAX_NOISE  RXPACC  ...  CIR1006  CIR1007  CIR1008  CIR1009  CIR1010  \\\n",
      "0      967.0   611.0  ...    279.0    458.0    183.0    158.0    198.0   \n",
      "1     1133.0   447.0  ...    144.0    334.0    290.0    228.0    187.0   \n",
      "2      894.0   723.0  ...     32.0    373.0    224.0    174.0    124.0   \n",
      "3     1127.0  1024.0  ...    252.0    173.0    198.0    160.0    434.0   \n",
      "4     1744.0   276.0  ...    154.0    209.0    242.0    296.0     87.0   \n",
      "\n",
      "   CIR1011  CIR1012  CIR1013  CIR1014  CIR1015  \n",
      "0     87.0    296.0    505.0    307.0      0.0  \n",
      "1    213.0    202.0     89.0    103.0      0.0  \n",
      "2    329.0    207.0     96.0    218.0      0.0  \n",
      "3    397.0    290.0    155.0    342.0    256.0  \n",
      "4    178.0    314.0    247.0    292.0    256.0  \n",
      "\n",
      "[5 rows x 1028 columns]\n"
     ]
    }
   ],
   "source": [
    "# check current combined dataset\n",
    "print(f\"Current Combined dataset shape: {combined_data.shape}\")\n",
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2b27ed9-d781-43a0-a99c-cc97b57267f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Identify non-numeric columns\n",
    "non_numeric_cols = combined_data.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Print non-numeric columns\n",
    "print(\"Non-numeric columns:\")\n",
    "print(non_numeric_cols.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff73802-a5c7-4d72-b4c9-aa8da9a8226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns containing special characters in values:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Define special characters\n",
    "special_chars = r\"[!@#$%^&*()_\\-?/<>]\"\n",
    "\n",
    "# Find columns with special characters\n",
    "cols_with_special_chars = [col for col in combined_data.columns if combined_data[col].astype(str).str.contains(special_chars, regex=True).any()]\n",
    "\n",
    "# Print columns with special characters\n",
    "print(\"Columns containing special characters in values:\")\n",
    "print(cols_with_special_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31a14a4-1227-4620-aebf-2c65ef88fcc7",
   "metadata": {},
   "source": [
    "#### **PCA for feature reduction(lien's):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "907e7bd2-3d30-4f98-9b1c-ef4479ef985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NLOS     RANGE    FP_IDX       FP_AMP1      FP_AMP2      FP_AMP3  \\\n",
      "0  -0.5  0.068481 -0.654167  10584.478095 -1175.259524  1837.893952   \n",
      "1  -0.5 -3.171519  3.345833   3111.478095 -5112.259524 -5026.106048   \n",
      "2   0.5  4.028481  0.345833  -3772.521905 -6185.259524 -6260.106048   \n",
      "3   0.5 -0.351519  4.345833    374.478095 -3009.259524 -3848.106048   \n",
      "4  -0.5 -2.641519  0.345833   9717.478095  6669.740476  2319.893952   \n",
      "\n",
      "   STDEV_NOISE      CIR_PWR   MAX_NOISE    RXPACC  ...     CIR1006  \\\n",
      "0    -8.284571  2065.309786 -349.096524   -5.2725  ...   21.544643   \n",
      "1    -8.284571  9178.309786 -183.096524 -169.2725  ... -113.455357   \n",
      "2   -12.284571  4909.309786 -422.096524  106.7275  ... -225.455357   \n",
      "3     3.715429 -1041.690214 -189.096524  407.7275  ...   -5.455357   \n",
      "4    -4.284571  1590.309786  427.903476 -340.2725  ... -103.455357   \n",
      "\n",
      "      CIR1007    CIR1008    CIR1009     CIR1010     CIR1011    CIR1012  \\\n",
      "0  190.769167 -66.123929 -67.917143  -41.445476 -153.034286  41.611905   \n",
      "1   66.769167  40.876071   2.082857  -52.445476  -27.034286 -52.388095   \n",
      "2  105.769167 -25.123929 -51.917143 -115.445476   88.965714 -47.388095   \n",
      "3  -94.230833 -51.123929 -65.917143  194.554524  156.965714  35.611905   \n",
      "4  -58.230833  -7.123929  70.082857 -152.445476  -62.034286  59.611905   \n",
      "\n",
      "      CIR1013     CIR1014     CIR1015  \n",
      "0  261.809357   53.826405  -90.203429  \n",
      "1 -154.190643 -150.173595  -90.203429  \n",
      "2 -147.190643  -35.173595  -90.203429  \n",
      "3  -88.190643   88.826405  165.796571  \n",
      "4    3.809357   38.826405  165.796571  \n",
      "\n",
      "[5 rows x 1028 columns]\n"
     ]
    }
   ],
   "source": [
    "# generate a copy for PCA \n",
    "pca_data = combined_data.copy()\n",
    "\n",
    "# Step 1: Compute the mean (ð›) for each column and center the data\n",
    "mean_vals = pca_data.mean(axis=0)   # Compute mean for each feature\n",
    "centered_data = pca_data - mean_vals    # Center the data by subtracting the mean\n",
    "print(centered_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "665f1814-c965-4579-af46-a7b3961d8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 2: Calculate the covariance matrix\n",
    "cov_matrix = np.cov(centered_data.T)  # Covariance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ed56d86-a10d-45c5-9d4c-d33d2257dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Find eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89d76de5-5bca-4a7b-ba96-65160bc9c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Sort eigenvectors based on eigenvalues (descending order)\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]  # Get indices of sorted eigenvalues\n",
    "eigenvalues = eigenvalues[sorted_indices]  # Sort eigenvalues\n",
    "eigenvectors = eigenvectors[:, sorted_indices]  # Sort eigenvectors accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c856241-ec36-45c1-898e-46e127288f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Select the top k principal components for dimensionality reduction\n",
    "explained_variance_ratio = eigenvalues / np.sum(eigenvalues)  # Compute variance ratio\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)  # Compute cumulative variance\n",
    "k = np.argmax(cumulative_variance >= 0.95) + 1  # Select k PCs that retain 95% variance\n",
    "top_k_eigenvectors = eigenvectors[:, :k]  # Extract top k eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "994824a4-b700-46d5-b6fe-e7354d35d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Project the data onto the selected principal components\n",
    "pca_data = np.dot(centered_data, top_k_eigenvectors)  # New dataset with reduced dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "361ae5ef-fee2-43be-9e87-edbeed7872e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign feature names to the principal components\n",
    "pca_feature_names = [combined_data.columns[np.argmax(abs(top_k_eigenvectors[:, i]))] for i in range(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59b5f940-69cd-4be6-8c04-4a03f32c6ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the transformed data into a DataFrame with feature-based names\n",
    "pca_df = pd.DataFrame(pca_data, columns=pca_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abbd37b9-2ab5-400e-8d9c-8ffe39a999de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Shape: (42000, 37)\n",
      "Reduced Data Shape: (42000, 37)\n",
      "Explained Variance by 37 PCs: 0.9507\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(f\"Original Data Shape: {pca_data.shape}\")\n",
    "print(f\"Reduced Data Shape: {pca_df.shape}\")\n",
    "print(f\"Explained Variance by {k} PCs: {cumulative_variance[k-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6d59497-6f94-4760-a81e-7763ebec0018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CIR_PWR       FP_AMP2        CIR746       CIR749       CIR753  \\\n",
      "0   3386.432268 -14010.810445   6696.255997 -2994.301662  5013.270382   \n",
      "1 -25211.032846  15485.323901   7584.883629  7528.293646  9002.227168   \n",
      "2 -11518.997733  15024.755373  12090.141478  -620.407129  4393.560546   \n",
      "3  -6011.290735  14757.546733     65.982138  5330.611182  2077.111037   \n",
      "4   3016.688967 -19785.758466  -3611.328990 -6632.572121  2564.297356   \n",
      "\n",
      "        CIR751       CIR752       CIR751      FP_AMP1       CIR753  ...  \\\n",
      "0 -4346.186792  1063.425598   -24.123417 -8588.983555  3716.470863  ...   \n",
      "1 -2270.167968  2291.911975  -148.339989 -3963.637766  8548.169521  ...   \n",
      "2 -1786.441455 -1354.733395  1358.080263 -1101.967653 -4335.936147  ...   \n",
      "3 -4919.782495   890.070749  1982.166910 -3083.771847  2289.133716  ...   \n",
      "4 -2358.173939   428.188749  4589.031078 -5464.550770 -1328.727111  ...   \n",
      "\n",
      "        CIR765       CIR743       CIR770       CIR769       CIR770  \\\n",
      "0  -386.815902 -2450.568632  -513.582577    83.992724  1085.680125   \n",
      "1   237.718386 -1938.691467  3457.733146  3454.059279  -782.292070   \n",
      "2 -1581.876711 -1565.738553   890.114334  1397.463019 -2759.627359   \n",
      "3  -249.802646  -607.896019   -16.779835  1526.795129  1230.300716   \n",
      "4   710.536905  1537.250123  1195.861957   321.768338   450.725970   \n",
      "\n",
      "       CIR771      CIR_PWR       CIR772       CIR776       CIR775  \n",
      "0  645.282850   466.969782 -1100.880062  1329.945618    93.759838  \n",
      "1  914.231429  1910.747516  1104.421795   183.115534 -3470.568234  \n",
      "2 -827.792595  -576.729210 -1327.718761 -1391.797396  1633.795770  \n",
      "3 -639.919148   220.587216  -130.847190  -678.279285  -486.575032  \n",
      "4   99.209565   128.880229   199.003099  -468.172894  -803.301204  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea084358-b67b-43f0-be8a-03edda2dfcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIR_PWR\n",
      "FP_AMP2\n",
      "CIR746\n",
      "CIR749\n",
      "CIR753\n",
      "CIR751\n",
      "CIR752\n",
      "CIR751\n",
      "FP_AMP1\n",
      "CIR753\n",
      "CIR754\n",
      "CIR755\n",
      "CIR756\n",
      "CIR757\n",
      "CIR756\n",
      "CIR757\n",
      "CIR759\n",
      "CIR760\n",
      "CIR761\n",
      "CIR748\n",
      "CIR761\n",
      "CIR762\n",
      "CIR762\n",
      "CIR763\n",
      "FP_AMP3\n",
      "CIR764\n",
      "CIR765\n",
      "CIR765\n",
      "CIR743\n",
      "CIR770\n",
      "CIR769\n",
      "CIR770\n",
      "CIR771\n",
      "CIR_PWR\n",
      "CIR772\n",
      "CIR776\n",
      "CIR775\n"
     ]
    }
   ],
   "source": [
    "for col in pca_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed44fc95-2a7a-4415-8ae2-9dbb38e60245",
   "metadata": {},
   "source": [
    "#### **PCA for feature reduction(jf's):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc63adbe-da0b-4b09-89f0-3fd3b0a483b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "for col in combined_data.columns:\n",
    "    if is_numeric_dtype(combined_data[col]):\n",
    "        print('%s:' % (col))\n",
    "        print('\\t Mean = %.2f' % combined_data[col].mean())\n",
    "        print('\\t Standard deviation = %.2f' % combined_data[col].std())\n",
    "        print('\\t Minimum = %.2f' % combined_data[col].min())\n",
    "        print('\\t Maximum = %.2f' % combined_data[col].max())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d508451-7217-420f-b86a-fa28ba09a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82839061-7fe9-41ef-b637-e6ff1a232e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariance:')\n",
    "combined_data.cov(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59790ae1-7c6b-4311-9577-c47a0e5034c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlation:') \n",
    "combined_data.corr(numeric_only=True) #range -1 to +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba022a-1b59-4609-8e29-2c02a92d01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090328e9-1e4f-45bc-855e-338cf5c4ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the occurrences of NLOS and LOS\n",
    "nlos_count = combined_data['NLOS'].value_counts()[1]\n",
    "los_count = combined_data['NLOS'].value_counts()[0]\n",
    "\n",
    "# Print the counts\n",
    "print(f'NLOS count: {nlos_count}')\n",
    "print(f'LOS count: {los_count}')\n",
    "\n",
    "# Plot the distribution of the target variable (NLOS)\n",
    "plt.figure(figsize=(6, 4))\n",
    "combined_data['NLOS'].value_counts().plot(kind='bar', color=['blue', 'orange'])\n",
    "plt.title('Distribution of NLOS (0 = LOS, 1 = NLOS)')\n",
    "plt.xlabel('NLOS')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0192e81-fefa-475f-b2c2-dc65ec677a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all numerical features\n",
    "numerical_features = [\n",
    "    'RANGE', 'FP_IDX', 'FP_AMP1', 'FP_AMP2', 'FP_AMP3', \n",
    "    'STDEV_NOISE', 'CIR_PWR', 'MAX_NOISE', 'RXPACC', \n",
    "    'CH', 'FRAME_LEN', 'PREAM_LEN', 'BITRATE', 'PRFR'\n",
    "]\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(18, 14))\n",
    "for i, feature in enumerate(numerical_features, 1):\n",
    "    plt.subplot(4, 4, i)\n",
    "    plt.hist(combined_data[feature], bins=30, color='blue', alpha=0.7)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "# Adjust layout for readability\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b6937-2b85-4ac8-9180-fdb8263aba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = combined_data[numerical_features].corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ddb5ab-08b6-4505-b288-d604bed7e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplots for numerical features\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(18, 14))\n",
    "for i, feature in enumerate(numerical_features, 1):\n",
    "    plt.subplot(4, 4, i)\n",
    "    sns.boxplot(y=combined_data[feature], color='orange')\n",
    "    plt.title(f'Boxplot of {feature}')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b240cbe-ae03-4a84-9d3c-bc2990396cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CIR values for a few samples\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(5):  # Plot first 5 samples\n",
    "    plt.plot(combined_data.loc[i, 'CIR1':'CIR1015'], label=f'Sample {i+1}')\n",
    "plt.title('CIR Values for First 5 Samples')\n",
    "plt.xlabel('CIR Index')\n",
    "plt.ylabel('CIR Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e8f88-460c-42ec-b377-03284319d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "missing_data = combined_data.isnull().sum()\n",
    "\n",
    "# Display columns with missing values\n",
    "if missing_data.sum() > 0:\n",
    "    print(\"Missing Data:\")\n",
    "    print(missing_data[missing_data > 0])\n",
    "else:\n",
    "    print(\"No missing data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93826bc-5684-40c9-b4cb-4e825b651778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicate_rows = combined_data.duplicated()\n",
    "\n",
    "# Display the number of duplicate rows\n",
    "print(f\"Number of duplicate rows: {duplicate_rows.sum()}\")\n",
    "\n",
    "# Display duplicate rows\n",
    "print(\"Duplicate Data:\")\n",
    "print(combined_data[duplicate_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9852248-f9e8-4264-9cba-1e107ee8885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance of each column\n",
    "variances = combined_data.var()\n",
    "\n",
    "# Identify columns with zero or very low variance\n",
    "low_variance_columns = variances[variances < 1e-10].index.tolist()\n",
    "\n",
    "print(\"Columns with low variance:\")\n",
    "print(low_variance_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c7ba9-539b-4879-a42f-6327673f167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with low variance\n",
    "data_cleaned = combined_data.drop(columns=low_variance_columns)\n",
    "\n",
    "print(f\"Shape after dropping low-variance columns: {data_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801ed2f-8fab-410d-9ed1-3c735e00fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "numerical_features = [\n",
    "    'RANGE', 'FP_IDX', 'FP_AMP1', 'FP_AMP2', 'FP_AMP3', \n",
    "    'STDEV_NOISE', 'CIR_PWR', 'MAX_NOISE', 'RXPACC', \n",
    "    'FRAME_LEN', 'PREAM_LEN'\n",
    "]\n",
    "\n",
    "z_scores = data_cleaned[numerical_features].apply(zscore)\n",
    "\n",
    "# Identify outliers (absolute Z-score > 3)\n",
    "outliers = (abs(z_scores) > 3).any(axis=1)\n",
    "\n",
    "# Display rows with outliers\n",
    "print(data_cleaned[outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597f576e-7669-4d31-9690-00d505dd2dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with outliers\n",
    "data_cleaned = data_cleaned[~outliers]\n",
    "print(data_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d568cc2-8569-492e-93e4-75150994ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the class attribute (NLOS)\n",
    "data_without_class = combined_data.drop(columns=['NLOS'])\n",
    "\n",
    "# Display the dataset without the class attribute\n",
    "print(data_without_class.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e6ce0d-6e8f-4a5f-bb3f-60de38d03a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select non-CIR numerical columns for visualization\n",
    "non_cir_columns = ['RANGE', 'FP_AMP1', 'FP_AMP2', 'FP_AMP3', 'STDEV_NOISE', 'CIR_PWR', 'MAX_NOISE', 'RXPACC', 'CH', 'FRAME_LEN', 'PREAM_LEN', 'BITRATE', 'PRFR']\n",
    "\n",
    "# Plot boxplots for non-CIR numerical columns\n",
    "plt.figure(figsize=(14, 8))\n",
    "data_without_class[non_cir_columns].boxplot()\n",
    "plt.title('Boxplot of Non-CIR Numerical Attributes')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d82741-b07e-4cd9-9308-72e175d57147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance of each column\n",
    "variances = data_without_class.var()\n",
    "\n",
    "# Identify columns with zero or very low variance\n",
    "low_variance_columns = variances[variances < 1e-10].index.tolist()\n",
    "\n",
    "print(\"Columns with low variance:\")\n",
    "print(low_variance_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b933c-7581-42a2-b1e7-d4fc9291abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with low variance\n",
    "data_without_class = data_without_class.drop(columns=low_variance_columns)\n",
    "\n",
    "print(f\"Shape after dropping low-variance columns: {data_without_class.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678aa14-eefa-4cd6-bf3c-14e6abdbf819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert data to numeric\n",
    "data_numeric = data_without_class.select_dtypes(include=['number'])\n",
    "\n",
    "# 2. Calculate Z-scores\n",
    "Z = (data_numeric - data_numeric.mean()) / data_numeric.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7824a0-0cb2-428e-937c-7234d7a924fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Identify and remove outliers\n",
    "print('Number of rows before discarding outliers = %d' % (Z.shape[0]))\n",
    "\n",
    "# Remove rows with any Z-score outside the range [-3, 3]\n",
    "Z2 = Z.loc[((Z > -3).sum(axis=1) == Z.shape[1]) & ((Z <= 3).sum(axis=1) == Z.shape[1]), :]\n",
    "\n",
    "print('Number of rows after discarding outliers = %d' % (Z2.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be813f7c-1542-411c-b6f0-05a7ac6eebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data_without_class.loc[Z2.index]\n",
    "# Display the cleaned dataset\n",
    "print(\"Cleaned dataset:\")\n",
    "print(data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc14cd-7c2f-4e68-af89-1fbbb1447182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Aggregate CIR columns (CIR1 to CIR1015)\n",
    "# Ensure we are working with a copy of the DataFrame\n",
    "data_cleaned = data_cleaned.copy()\n",
    "\n",
    "# 1. Aggregation\n",
    "# Aggregate CIR columns (CIR1 to CIR1015)\n",
    "cir_columns = [f'CIR{i}' for i in range(1, 1016)]\n",
    "data_cleaned.loc[:, 'CIR_MEAN'] = data_cleaned[cir_columns].mean(axis=1)\n",
    "data_cleaned.loc[:, 'CIR_STD'] = data_cleaned[cir_columns].std(axis=1)\n",
    "data_cleaned.loc[:, 'CIR_MAX'] = data_cleaned[cir_columns].max(axis=1)\n",
    "data_cleaned.loc[:, 'CIR_MIN'] = data_cleaned[cir_columns].min(axis=1)\n",
    "\n",
    "# Drop the original CIR columns (optional)\n",
    "#data_cleaned = data_cleaned.drop(columns=cir_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893eeddf-e864-4458-8f1a-7bdfcf2495db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Sampling\n",
    "# Randomly sample 10% of the dataset\n",
    "sampled_data = data_cleaned.sample(frac=0.1, random_state=42)\n",
    "print(f\"Shape of sampled dataset: {sampled_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83465f16-267a-47c3-af70-1397bcf0ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 3. Discretization\n",
    "# Discretize the RANGE feature into 5 bins\n",
    "data_cleaned.loc[:, 'RANGE_BIN'] = pd.cut(data_cleaned['RANGE'], bins=5, labels=[\"Very Low\", \"Low\", \"Medium\", \"High\", \"Very High\"])\n",
    "\n",
    "# Discretize the CIR_PWR feature into quartiles\n",
    "data_cleaned.loc[:, 'CIR_PWR_BIN'] = pd.qcut(data_cleaned['CIR_PWR'], q=4, labels=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"])\n",
    "\n",
    "# Display the final dataset\n",
    "print(data_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a99bba0-34b4-4be8-8468-c04734b9fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01711264-6d84-482a-b489-61bfcc650cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract CIR columns (CIR1 to CIR1015)\n",
    "cir_columns = [f'CIR{i}' for i in range(1, 1016)]\n",
    "cir_data = data[cir_columns]\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "pca.fit(cir_data)\n",
    "\n",
    "# Plot explained variance ratio\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_.cumsum(), marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by PCA Components')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Choose the number of components that explain >95% of the variance\n",
    "n_components = len(pca.explained_variance_ratio_[pca.explained_variance_ratio_.cumsum() <= 0.95])\n",
    "print(f\"Number of components to retain: {n_components}\")\n",
    "\n",
    "# Apply PCA with selected number of components\n",
    "pca = PCA(n_components=n_components)\n",
    "cir_reduced = pca.fit_transform(cir_data)\n",
    "\n",
    "# Add reduced CIR features back to the dataset\n",
    "for i in range(n_components):\n",
    "    data[f'CIR_PC{i+1}'] = cir_reduced[:, i]\n",
    "\n",
    "# Drop original CIR columns (optional, to save memory)\n",
    "data.drop(columns=cir_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c8794e-ab86-423e-a147-421153be610b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
